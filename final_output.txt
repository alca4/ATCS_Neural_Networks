########################################
Attempting to configure model from file 'train.txt'

Model configured successfully!
Memory allocated
Weights intialized!
Printing configuration paramenters:

Number of activation layers: 4
Size of each activation layer: 28224 16 8 5 
The threshold function used will be: sigmoid
Current mode: training
Number of tests: 25
Weights will be initialized between -1 and 1
lambda is 0.1
The model will stop when it reached 1000000000 iterations or reaches a error lower than 0.0001

Tests loaded
Iteration: 100	Error: 0.196229392
Iteration: 200	Error: 0.050583991
Iteration: 300	Error: 0.020181999
Iteration: 400	Error: 0.011538085
Iteration: 500	Error: 0.007816703
Iteration: 600	Error: 0.005812529
Iteration: 700	Error: 0.004592616
Iteration: 800	Error: 0.003776650
Iteration: 900	Error: 0.003195789
Iteration: 1000	Error: 0.002763418
Iteration: 1100	Error: 0.002430129
Iteration: 1200	Error: 0.002165766
Iteration: 1300	Error: 0.001951157
Iteration: 1400	Error: 0.001773565
Iteration: 1500	Error: 0.001624175
Iteration: 1600	Error: 0.001496672
Iteration: 1700	Error: 0.001386403
Iteration: 1800	Error: 0.001289972
Iteration: 1900	Error: 0.001205083
Iteration: 2000	Error: 0.001130086
Iteration: 2100	Error: 0.001063409
Iteration: 2200	Error: 0.001003597
Iteration: 2300	Error: 0.000949551
Iteration: 2400	Error: 0.000900626
Iteration: 2500	Error: 0.000856409
Iteration: 2600	Error: 0.000816389
Iteration: 2700	Error: 0.000779992
Iteration: 2800	Error: 0.000746712
Iteration: 2900	Error: 0.000716135
Iteration: 3000	Error: 0.000687928
Iteration: 3100	Error: 0.000661817
Iteration: 3200	Error: 0.000637571
Iteration: 3300	Error: 0.000614996
Iteration: 3400	Error: 0.000593924
Iteration: 3500	Error: 0.000574210
Iteration: 3600	Error: 0.000555727
Iteration: 3700	Error: 0.000538363
Iteration: 3800	Error: 0.000522022
Iteration: 3900	Error: 0.000506615
Iteration: 4000	Error: 0.000492066
Iteration: 4100	Error: 0.000478305
Iteration: 4200	Error: 0.000465271
Iteration: 4300	Error: 0.000452908
Iteration: 4400	Error: 0.000441165
Iteration: 4500	Error: 0.000429999
Iteration: 4600	Error: 0.000419367
Iteration: 4700	Error: 0.000409233
Iteration: 4800	Error: 0.000399562
Iteration: 4900	Error: 0.000390325
Iteration: 5000	Error: 0.000381492
Iteration: 5100	Error: 0.000373038
Iteration: 5200	Error: 0.000364940
Iteration: 5300	Error: 0.000357175
Iteration: 5400	Error: 0.000349724
Iteration: 5500	Error: 0.000342567
Iteration: 5600	Error: 0.000335689
Iteration: 5700	Error: 0.000329074
Iteration: 5800	Error: 0.000322706
Iteration: 5900	Error: 0.000316572
Iteration: 6000	Error: 0.000310660
Iteration: 6100	Error: 0.000304957
Iteration: 6200	Error: 0.000299454
Iteration: 6300	Error: 0.000294140
Iteration: 6400	Error: 0.000289005
Iteration: 6500	Error: 0.000284041
Iteration: 6600	Error: 0.000279239
Iteration: 6700	Error: 0.000274592
Iteration: 6800	Error: 0.000270092
Iteration: 6900	Error: 0.000265733
Iteration: 7000	Error: 0.000261507
Iteration: 7100	Error: 0.000257410
Iteration: 7200	Error: 0.000253435
Iteration: 7300	Error: 0.000249576
Iteration: 7400	Error: 0.000245830
Iteration: 7500	Error: 0.000242191
Iteration: 7600	Error: 0.000238655
Iteration: 7700	Error: 0.000235217
Iteration: 7800	Error: 0.000231874
Iteration: 7900	Error: 0.000228621
Iteration: 8000	Error: 0.000225455
Iteration: 8100	Error: 0.000222373
Iteration: 8200	Error: 0.000219372
Iteration: 8300	Error: 0.000216447
Iteration: 8400	Error: 0.000213597
Iteration: 8500	Error: 0.000210819
Iteration: 8600	Error: 0.000208110
Iteration: 8700	Error: 0.000205467
Iteration: 8800	Error: 0.000202888
Iteration: 8900	Error: 0.000200371
Iteration: 9000	Error: 0.000197914
Iteration: 9100	Error: 0.000195514
Iteration: 9200	Error: 0.000193170
Iteration: 9300	Error: 0.000190879
Iteration: 9400	Error: 0.000188640
Iteration: 9500	Error: 0.000186452
Iteration: 9600	Error: 0.000184312
Iteration: 9700	Error: 0.000182219
Iteration: 9800	Error: 0.000180171
Iteration: 9900	Error: 0.000178168
Iteration: 10000	Error: 0.000176206
Iteration: 10100	Error: 0.000174287
Iteration: 10200	Error: 0.000172407
Iteration: 10300	Error: 0.000170566
Iteration: 10400	Error: 0.000168762
Iteration: 10500	Error: 0.000166995
Iteration: 10600	Error: 0.000165263
Iteration: 10700	Error: 0.000163566
Iteration: 10800	Error: 0.000161902
Iteration: 10900	Error: 0.000160270
Iteration: 11000	Error: 0.000158670
Iteration: 11100	Error: 0.000157100
Iteration: 11200	Error: 0.000155560
Iteration: 11300	Error: 0.000154049
Iteration: 11400	Error: 0.000152566
Iteration: 11500	Error: 0.000151111
Iteration: 11600	Error: 0.000149682
Iteration: 11700	Error: 0.000148278
Iteration: 11800	Error: 0.000146900
Iteration: 11900	Error: 0.000145547
Iteration: 12000	Error: 0.000144217
Iteration: 12100	Error: 0.000142911
Iteration: 12200	Error: 0.000141627
Iteration: 12300	Error: 0.000140365
Iteration: 12400	Error: 0.000139125
Iteration: 12500	Error: 0.000137905
Iteration: 12600	Error: 0.000136707
Iteration: 12700	Error: 0.000135528
Iteration: 12800	Error: 0.000134368
Iteration: 12900	Error: 0.000133228
Iteration: 13000	Error: 0.000132106
Iteration: 13100	Error: 0.000131002
Iteration: 13200	Error: 0.000129916
Iteration: 13300	Error: 0.000128847
Iteration: 13400	Error: 0.000127795
Iteration: 13500	Error: 0.000126760
Iteration: 13600	Error: 0.000125740
Iteration: 13700	Error: 0.000124736
Iteration: 13800	Error: 0.000123748
Iteration: 13900	Error: 0.000122775
Iteration: 14000	Error: 0.000121816
Iteration: 14100	Error: 0.000120871
Iteration: 14200	Error: 0.000119941
Iteration: 14300	Error: 0.000119024
Iteration: 14400	Error: 0.000118121
Iteration: 14500	Error: 0.000117231
Iteration: 14600	Error: 0.000116354
Iteration: 14700	Error: 0.000115489
Iteration: 14800	Error: 0.000114636
Iteration: 14900	Error: 0.000113796
Iteration: 15000	Error: 0.000112968
Iteration: 15100	Error: 0.000112151
Iteration: 15200	Error: 0.000111345
Iteration: 15300	Error: 0.000110550
Iteration: 15400	Error: 0.000109767
Iteration: 15500	Error: 0.000108994
Iteration: 15600	Error: 0.000108231
Iteration: 15700	Error: 0.000107479
Iteration: 15800	Error: 0.000106737
Iteration: 15900	Error: 0.000106004
Iteration: 16000	Error: 0.000105281
Iteration: 16100	Error: 0.000104568
Iteration: 16200	Error: 0.000103864
Iteration: 16300	Error: 0.000103169
Iteration: 16400	Error: 0.000102483
Iteration: 16500	Error: 0.000101805
Iteration: 16600	Error: 0.000101136
Iteration: 16700	Error: 0.000100476

SUCCESS: Model converged after 16773 iterations!
Error: 0.000099999

Model terminated due to reaching low enough error (<=0.000100000).
Final truth table:
0.993115316 0.004887590 0.004800935 0.003164897 0.003839806 | 1.000000000 0.000000000 0.000000000 0.000000000 0.000000000 
0.982786364 0.009959687 0.011502243 0.001866471 0.002046432 | 1.000000000 0.000000000 0.000000000 0.000000000 0.000000000 
0.993091802 0.004915121 0.004807594 0.003157235 0.003843127 | 1.000000000 0.000000000 0.000000000 0.000000000 0.000000000 
0.993324371 0.005232021 0.004831266 0.003140442 0.003708207 | 1.000000000 0.000000000 0.000000000 0.000000000 0.000000000 
0.993087980 0.004921740 0.004803498 0.003159520 0.003846028 | 1.000000000 0.000000000 0.000000000 0.000000000 0.000000000 

0.001727568 0.987768374 0.009895447 0.009121726 0.011685816 | 0.000000000 1.000000000 0.000000000 0.000000000 0.000000000 
0.003714678 0.984719270 0.002609955 0.004111427 0.009652125 | 0.000000000 1.000000000 0.000000000 0.000000000 0.000000000 
0.005049580 0.995757151 0.001639285 0.000928325 0.006309086 | 0.000000000 1.000000000 0.000000000 0.000000000 0.000000000 
0.014273862 0.995298843 0.000900653 0.000725546 0.003873993 | 0.000000000 1.000000000 0.000000000 0.000000000 0.000000000 
0.005021426 0.995748735 0.001648649 0.000931447 0.006320779 | 0.000000000 1.000000000 0.000000000 0.000000000 0.000000000 

0.010033702 0.001904157 0.985979762 0.001562529 0.005990415 | 0.000000000 0.000000000 1.000000000 0.000000000 0.000000000 
0.003207423 0.001202938 0.991656475 0.006120796 0.001213919 | 0.000000000 0.000000000 1.000000000 0.000000000 0.000000000 
0.003937812 0.000382233 0.993109861 0.007311461 0.002690419 | 0.000000000 0.000000000 1.000000000 0.000000000 0.000000000 
0.003861031 0.000394599 0.993116599 0.007290182 0.002620381 | 0.000000000 0.000000000 1.000000000 0.000000000 0.000000000 
0.001857144 0.008003830 0.989011403 0.005699733 0.000456965 | 0.000000000 0.000000000 1.000000000 0.000000000 0.000000000 

0.001207730 0.003971285 0.007595620 0.991562804 0.005357933 | 0.000000000 0.000000000 0.000000000 1.000000000 0.000000000 
0.006581650 0.009540470 0.003078877 0.989886800 0.001947955 | 0.000000000 0.000000000 0.000000000 1.000000000 0.000000000 
0.003918497 0.005534961 0.004449690 0.991205371 0.004462474 | 0.000000000 0.000000000 0.000000000 1.000000000 0.000000000 
0.002415439 0.001329838 0.005740519 0.991861407 0.008225206 | 0.000000000 0.000000000 0.000000000 1.000000000 0.000000000 
0.001208092 0.004069573 0.007415337 0.991611589 0.005394794 | 0.000000000 0.000000000 0.000000000 1.000000000 0.000000000 

0.001713472 0.005716963 0.004561629 0.005417748 0.989848732 | 0.000000000 0.000000000 0.000000000 0.000000000 1.000000000 
0.001714286 0.005710529 0.004562440 0.005413666 0.989860192 | 0.000000000 0.000000000 0.000000000 0.000000000 1.000000000 
0.001625398 0.003665774 0.004020246 0.005093026 0.989297776 | 0.000000000 0.000000000 0.000000000 0.000000000 1.000000000 
0.002429587 0.004755968 0.004977780 0.005532007 0.992762449 | 0.000000000 0.000000000 0.000000000 0.000000000 1.000000000 
0.001697410 0.005663506 0.004570973 0.005467516 0.989844890 | 0.000000000 0.000000000 0.000000000 0.000000000 1.000000000 

Average error is 0.000099999
Took 1880.062200000s to train
Model weights saved to file trained_model.txt!
